}
#Intervention
if(parms[["int_round"]] > 0) {
usage = data.frame("time" = seq(0,7000),
"PopUsage1" = c(rep(parms[["sigma_mat"]][1,2] , 365*3), rep(parms[["sigma_mat"]][1,3] , 365*3), rep(parms[["sigma_mat"]][1,4] , 365*3),
rep(parms[["sigma_mat"]][1,5], 365*3), rep(parms[["sigma_mat"]][1,6] , 365*3), rep(parms[["sigma_mat"]][1,7] , (365*3)+(7001-(365*3)*6))),
"PopUsage2" = c(rep(parms[["sigma_mat"]][2,2] , 365*3), rep(parms[["sigma_mat"]][2,3] , 365*3), rep(parms[["sigma_mat"]][2,4] , 365*3),
rep(parms[["sigma_mat"]][2,5], 365*3), rep(parms[["sigma_mat"]][2,6] , 365*3), rep(parms[["sigma_mat"]][2,7] , (365*3)+(7001-(365*3)*6))),
"PopUsage3" = c(rep(parms[["sigma_mat"]][3,2] , 365*3), rep(parms[["sigma_mat"]][3,3] , 365*3), rep(parms[["sigma_mat"]][3,4] , 365*3),
rep(parms[["sigma_mat"]][3,5], 365*3), rep(parms[["sigma_mat"]][3,6] , 365*3), rep(parms[["sigma_mat"]][3,7] , (365*3)+(7001-(365*3)*6))))
}
usage$totusage = rowSums(usage[2:4])
usage$reduc_use = parms[["sigma1"]] + parms[["sigma2"]] + parms[["sigma3"]] - usage$totusage
return(usage)
}
# Baseline Parms ----------------------------------------------------------
init <- c(X = 0.99, Wt = 1-0.99, R1 = 0, R2 = 0, R3 = 0,
R12 = 0, R13 = 0, R23 = 0,
R123 = 0)
parms = list(lambda = 1/365*(2), int_round = 1,
beta = 5, sigma1 = 0.25, sigma2 = 0.25, sigma3 = 0.25,
r_wt = 1/12, r_r = 1/10,  r_rr = 1/9,  r_rrr = 1/8,
r_t = 1/7, eta_wr = 0.3, eta_rw = 0.04,
eta_rr = 0.01, eta_rrr = 0.01,
c1 = 0.945, c2 = 0.925, c3 = 0.85,
c12 = 0.845, c13 = 0.825, c23 = 0.75,
c123 = 0.7,
PED = matrix(c(-1, 0.4, 0.4,
0.4, -1, 0.4,
0.4, 0.4, -1), #Be aware of this matrix
nrow = 3, ncol = 3, byrow = T),
eff_tax = matrix(c(0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0),
nrow = 3, ncol = 6, byrow = T),
sigma_mat = matrix(c(0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0),
nrow = 3, ncol = 7, byrow = T),
t_n = 3000, time_between = Inf, rho = 0.05, base_tax = 0.5)
# The Function ------------------------------------------------------------
low_parm <- c(1/3650*(2), #lambda
0, #beta
0, #sigma1
0, #sigma2
0, #sigma3
1/50, #r_wt
1/50, #r_r
1/50, #r_rr
1/50, #r_rrr
1/50, #r_t
0.03, #eta_wr
0.004, #eta_rw
0.001, #eta_rr
0.001, #eta_rrr
0.5, #c1
0.5, #c2
0.5, #c3
0.5, #c12
0.5, #c13
0.5, #c23
0.5, #c123
0, #rho
0) #baseline tax
high_parm <- c(1/36.5*(2), #lambda
10, #beta
1, #sigma1
1, #sigma2
1, #sigma3
1/2, #r_wt
1/2, #r_r
1/2, #r_rr
1/2, #r_rrr
1/2, #r_t
3, #eta_wr
0.4, #eta_rw
0.1, #eta_rr
0.1, #eta_rrr
1, #c1
1, #c2
1, #c3
1, #c12
1, #c13
1, #c23
1, #c123
1, #rho
1) #baseline tax
#Creating the Parm Dataframe
parm_data <- data.frame(t(replicate(10000, runif(23, low_parm, high_parm))))
colnames(parm_data) <- c("lambda", "beta", "sigma1", "sigma2", "sigma3",
"r_wt", "r_r", "r_rr", "r_rrr","r_t",
"eta_wr", "eta_rw", "eta_rr", "eta_rrr",
"c1", "c2", "c3", "c12", "c13", "c23", "c123",
"rho", "base_tax")
for(i in 1:nrow(parm_data)) {
if(sum(parm_data[c("sigma1", "sigma2", "sigma3")][i,]) > 1) {
parm_data[c("sigma1", "sigma2", "sigma3")][i,] <- parm_data[c("sigma1", "sigma2", "sigma3")][i,]/
(sum(parm_data[c("sigma1", "sigma2", "sigma3")][i,]) + runif(1, 0, 1))
}
}
parm_data[c("eta_wr", "eta_rw", "eta_rr", "eta_rrr")] <- t(sapply(1:nrow(parm_data), function(x)
sort(as.numeric(parm_data[c("eta_wr", "eta_rw", "eta_rr", "eta_rrr")][x,]), decreasing = T)))
parm_data[c("r_wt", "r_r", "r_rr", "r_rrr", "r_t")] <- t(sapply(1:nrow(parm_data), function(x)
sort(as.numeric(parm_data[c("r_wt", "r_r", "r_rr", "r_rrr", "r_t")][x,]), decreasing = F)))
parm_data[c("c1", "c2", "c3")] <- t(sapply(1:nrow(parm_data), function(x)
sample(sort(as.numeric(parm_data[c("c1", "c2", "c3", "c12", "c13", "c23", "c123")][x,]), decreasing = T)[1:3],
size = 3, replace = FALSE)))
parm_data[c("c12", "c13", "c23")] <-  t(sapply(1:nrow(parm_data), function(x)
sample(sort(as.numeric(parm_data[c("c1", "c2", "c3", "c12", "c13", "c23", "c123")][x,]), decreasing = T)[4:6],
size = 3, replace = FALSE)))
parm_data["c123"] <- sapply(1:nrow(parm_data), function(x)
sort(as.numeric(parm_data[c("c1", "c2", "c3", "c12", "c13", "c23", "c123")][x,]), decreasing = T)[7])
parm_data_comb <- data.frame(parm_data, t_n = 3000, int_round = 0,
time_between = Inf)
# Creating the Parallel Montonicity Function ------------------------------
mono_func <- function(n, parms_frame, init, amr_ode, usage_fun, multi_int_fun, low_parm, high_parm, agg_func, thresh, ode_wrapper) {
parms_base = as.list(parms_frame[n,])
parms_base = append(parms_base, parms["PED"])
parms_base = append(parms_base, parms["eff_tax"])
parms_base = append(parms_base, parms["sigma_mat"])
#Run Baseline
run_base <- ode_wrapper(y = init, func = amr_ode, times = seq(0, 10000), parms = parms_base)[[1]]
run_base_agg <- agg_func(run_base)
values <- tail(run_base_agg, 1)
if(values[4] == 0 & values[5] == 0 & values[6] == 0) {
while(values[4] == 0 & values[5] == 0 & values[6] == 0) {
parms_base[c(1:23)] <- as.list(runif(23, low_parm, high_parm))
if(sum(unlist(parms_base[c("sigma1", "sigma2", "sigma3")])) > 1) {
parms_base[c("sigma1", "sigma2", "sigma3")] <- as.list(unlist(parms_base[c("sigma1", "sigma2", "sigma3")])/
(sum(unlist(parms_base[c("sigma1", "sigma2", "sigma3")])) + runif(1, 0, 1)))
}
parms_base[c("eta_wr", "eta_rw", "eta_rr", "eta_rrr")] <- as.list(sort(as.numeric(parms_base[c("eta_wr", "eta_rw", "eta_rr", "eta_rrr")]), decreasing = T))
parms_base[c("r_wt", "r_r", "r_rr", "r_rrr", "r_t")] <- as.list(sort(as.numeric(parms_base[c("r_wt", "r_r", "r_rr", "r_rrr", "r_t")]), decreasing = F))
parms_base[c("c1", "c2", "c3")] <-
as.list(sample(sort(as.numeric(parms_base[c("c1", "c2", "c3", "c12", "c13", "c23", "c123")]), decreasing = T)[1:3]), size = 3, replace = F)
parms_base[c("c12", "c13", "c23")] <-
as.list(sample(sort(as.numeric(parms_base[c("c1", "c2", "c3", "c12", "c13", "c23", "c123")]), decreasing = T)[4:6]), size = 3, replace = F)
parms_base["c123"] <-
as.list(sort(as.numeric(parms_base[c("c1", "c2", "c3", "c12", "c13", "c23", "c123")]), decreasing = T)[7])
run_base <- ode_wrapper(y = init, func = amr_ode, times = seq(0, 10000), parms = parms_base)[[1]]
run_base_agg <- agg_func(run_base)
values <- tail(run_base_agg, 1)
}
}
run <- run_base[run_base[,1] > parms_base[["t_n"]],]
run_base_agg <- run_base_agg[run_base_agg[,1] > parms_base[["t_n"]],]
#Identifying the order of the resistances
res_order_vec <- c(names(values[4:6])[which.max(values[4:6])],
names(values[4:6])[setdiff(1:3, c(which.min(values[4:6]), which.max(values[4:6])))],
names(values[4:6])[which.min(values[4:6])])
#Storing info for the integrals
base_tot_inf <- signif(sum(run[3:10]), 5)
base_int_res <- signif(sum(rowMeans(run_base_agg[4:6]), 5))
#Need to calculate a different baseline for each scenario for antibiotic usage
store_vec_res <- c()
store_vec_inf <- c()
store_vec_shan <- c()
store_vec_avganti <- c()
for(i in 1:10){
parms = parms_base
if(i == 1) {
parms[["eff_tax"]][,] <- parms[["base_tax"]]
parms[["int_round"]] <- 1
out_run <- ode_wrapper(y = init, func = amr_ode, times = seq(0, 10000), parms = parms)
out <- out_run[[1]]
parms <- out_run[[2]]
}
if(i >= 2 & i <= 4) {
parms[["eff_tax"]][as.numeric(substr(res_order_vec[i-1], 2, 2)), c(1:6)] <- parms[["base_tax"]]
parms[["int_round"]] <- 1
out_run <- ode_wrapper(y = init, func = amr_ode, times = seq(0, 10000), parms = parms)
out <- out_run[[1]]
parms <- out_run[[2]]
}
if(i >= 5 & i <= 10) {
diff <- multi_int_fun(i-4, 365*3, parms, init, amr_ode, agg_func, ode_wrapper)
out <- diff[[1]]
parms <- diff[[2]]
}
data_temp <- out[out[,1] > parms[["t_n"]],]
data_temp_agg <- agg_func(data_temp)
out_vec <- signif(c(sum(data_temp[3:10]),
sum(rowMeans(data_temp_agg[4:6]))), 5)
reduc_usage_vec <- sum(usage_fun(parms)[,6])
#Aggregation
out$aggR1 <- out$R1 + out$R12 + out$R13 + out$R123
out$aggR2 <- out$R2 + out$R12 + out$R23 + out$R123
out$aggR3 <- out$R3 + out$R13 + out$R23 + out$R123
#Determine the X% Thresholds that you want to be under
thresholds <- unlist(out[parms[["t_n"]]-1, 11:13]*thresh)
under_thresh <- sweep(out[out[,1] > parms[["t_n"]],][,11:13], 2, thresholds)
#Calculate the number of days you are under said threshold
under_50 <- c(nrow(under_thresh[under_thresh$aggR1 < 0,]),
nrow(under_thresh[under_thresh$aggR2 < 0,]),
nrow(under_thresh[under_thresh$aggR3 < 0,]))
#Find the Sum and make each value proportionate to one another
prop_vec <- sum(under_50) / (10000 - parms[["t_n"]])
prop_vec_shan <- under_50 / sum(under_50)
prop_vec_shan <- prop_vec_shan[prop_vec_shan != 0]
#Store Computation Vectors
store_vec_inf[i] <- (out_vec[1] - base_tot_inf)/reduc_usage_vec
store_vec_res[i] <- (base_int_res - out_vec[2])/reduc_usage_vec
store_vec_shan[i] <- -sum(sapply(1:length(prop_vec_shan), function(x) prop_vec_shan[x]*log(prop_vec_shan[x])))
store_vec_avganti[i] <- prop_vec
}
output <- c(store_vec_inf, store_vec_res, store_vec_shan, store_vec_avganti, parms_base[c(1:29)])
names(output) <- c("flat_inf", "singleHR_inf", "singleMR_inf", "singleLR_inf", "diff1_inf", "diff2_inf", "diff3_inf", "diff4_inf", "diff5_inf", "diff6_inf",
"flat_res", "singleHR_res", "singleMR_res", "singleLR_res", "diff1_res", "diff2_res", "diff3_res", "diff4_res", "diff5_res", "diff6_res",
"flat_shan", "singleHR_shan", "singleMR_shan", "singleLR_shan", "diff1_shan", "diff2_shan", "diff3_shan", "diff4_shan", "diff5_shan", "diff6_shan",
"flat_avganti", "singleHR_avganti", "singleMR_avganti", "singleLR_avganti", "diff1_avganti", "diff2_avganti", "diff3_avganti", "diff4_avganti", "diff5_avganti", "diff6_avganti",
names(parms_base[c(1:29)]))
return(output)
}
# Run the Model ----------------------------------------------------------
start_time <- Sys.time()
test <- mclapply(1:10,
FUN = mono_func,
parms_frame = parm_data_comb,
init = c(X = 0.99, Wt = 1-0.99, R1 = 0, R2 = 0, R3 = 0,
R12 = 0, R13 = 0, R23 = 0,
R123 = 0),
amr_ode = amr,
usage_fun = usage_fun,
multi_int_fun = multi_int_fun,
low_parm = low_parm,
high_parm = high_parm,
agg_func = agg_func,
ode_wrapper = ode_wrapper,
thresh = 0.5,
mc.cores = 10)
start_time <- Sys.time()
test <- mclapply(1:10,
FUN = mono_func,
parms_frame = parm_data_comb,
init = c(X = 0.99, Wt = 1-0.99, R1 = 0, R2 = 0, R3 = 0,
R12 = 0, R13 = 0, R23 = 0,
R123 = 0),
amr_ode = amr,
usage_fun = usage_fun,
multi_int_fun = multi_int_fun,
low_parm = low_parm,
high_parm = high_parm,
agg_func = agg_func,
ode_wrapper = ode_wrapper,
thresh = 0.5,
mc.cores = 10)
end_time <- Sys.time()
print(end_time - start_time)
ode_wrapper <- function(times, y, parms, func) {
sigma_mat = matrix(c(rep(parms[["sigma1"]], 7),
rep(parms[["sigma2"]], 7),
rep(parms[["sigma3"]], 7)),
nrow = 3, ncol = 7, byrow = T)
eff_tax <- parms[["eff_tax"]]; PED <- parms[["PED"]]
if(parms[["int_round"]] > 0 ) {
for(i in 1:parms[["int_round"]]) {
stor_sigma <- sigma_mat[,i]
if(sigma_mat[1,i] == 0 | sigma_mat[2,i] == 0 | sigma_mat[3,i] == 0) {
stor_sigma[stor_sigma == 0] = 0.01
}
sigma_mat[,(i+1):7] = c(stor_sigma[1]*(1 + ((eff_tax[1,i]*PED[1,1]) + (eff_tax[2,i]*PED[2,1]) + (eff_tax[3,i]*PED[3,1]))),
stor_sigma[2]*(1 + ((eff_tax[1,i]*PED[1,2]) + (eff_tax[2,i]*PED[2,2]) + (eff_tax[3,i]*PED[3,2]))),
stor_sigma[3]*(1 + ((eff_tax[1,i]*PED[1,3]) + (eff_tax[2,i]*PED[2,3]) + (eff_tax[3,i]*PED[3,3]))))
sigma_mat[sigma_mat < 0] = 0
if(colSums(sigma_mat)[i+1] > 1) {
sigma_mat[,(i+1):7] <- sigma_mat[,i+1]/colSums(sigma_mat)[i+1]
}
}
}
parms[["sigma_mat"]] <- sigma_mat
#Run the model
out <- data.frame(ode(y = init, func = func, times = times, parms = parms))
n_data <- ncol(out)-1
timing <- t(sapply(1:n_data, function(x)  out[max(which(!is.na(out[,x+1]))),]))
if(timing[1,1] != tail(times,1)) {
for(i in 1:n_data){
out[seq(timing[[1]]+2,tail(times,1)+1),i+1] <- timing[i,i+1]
}
}
out[out < 1e-10] <- 0
return(list(out, parms))
}
start_time <- Sys.time()
test <- mclapply(1:10,
FUN = mono_func,
parms_frame = parm_data_comb,
init = c(X = 0.99, Wt = 1-0.99, R1 = 0, R2 = 0, R3 = 0,
R12 = 0, R13 = 0, R23 = 0,
R123 = 0),
amr_ode = amr,
usage_fun = usage_fun,
multi_int_fun = multi_int_fun,
low_parm = low_parm,
high_parm = high_parm,
agg_func = agg_func,
ode_wrapper = ode_wrapper,
thresh = 0.5,
mc.cores = 10)
end_time <- Sys.time()
print(end_time - start_time)
3*60
180/34
install.packages(c("bayestestR", "broom", "bslib", "callr", "car", "checkmate", "cli", "cluster", "confintr", "cpp11", "crayon", "curl", "datawizard", "DBI", "dbplyr", "desc", "deSolve", "dotCall64", "dplyr", "dtplyr", "evaluate", "farver", "fields", "forcats", "foreign", "gargle", "generics", "ggplot2", "googlesheets4", "gtable", "haven", "Hmisc", "hms", "htmltools", "httr", "insight", "isoband", "jsonlite", "knitr", "lifecycle", "lme4", "maptools", "MASS", "Matrix", "MatrixModels", "metR", "mgcv", "modelr", "multcomp", "nlme", "nloptr", "nnet", "openssl", "pillar", "pkgload", "pracma", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "RCurl", "readr", "readxl", "reprex", "rlang", "rmarkdown", "rstudioapi", "rvest", "sandwich", "sass", "scales", "sensitivity", "sp", "spam", "stringi", "stringr", "Surrogate", "survival", "testthat", "tibble", "tidyr", "tidyselect", "tidyverse", "tinytex", "vctrs", "viridisLite", "vroom", "xfun", "zoo"))
install.packages(c("bayestestR", "broom", "bslib", "callr", "car", "checkmate", "cli", "cluster", "confintr", "cpp11", "crayon", "curl", "datawizard", "DBI", "dbplyr", "desc", "deSolve", "dotCall64", "dplyr", "dtplyr", "evaluate", "farver", "fields", "forcats", "foreign", "gargle", "generics", "ggplot2", "googlesheets4", "gtable", "haven", "Hmisc", "hms", "htmltools", "httr", "insight", "isoband", "jsonlite", "knitr", "lifecycle", "lme4", "maptools", "MASS", "Matrix", "MatrixModels", "metR", "mgcv", "modelr", "multcomp", "nlme", "nloptr", "nnet", "openssl", "pillar", "pkgload", "pracma", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "RCurl", "readr", "readxl", "reprex", "rlang", "rmarkdown", "rstudioapi", "rvest", "sandwich", "sass", "scales", "sensitivity", "sp", "spam", "stringi", "stringr", "Surrogate", "survival", "testthat", "tibble", "tidyr", "tidyselect", "tidyverse", "tinytex", "vctrs", "viridisLite", "vroom", "xfun", "zoo"))
install.packages(c("bayestestR", "broom", "bslib", "callr", "car", "checkmate", "cli", "cluster", "confintr", "cpp11", "crayon", "curl", "datawizard", "DBI", "dbplyr", "desc", "deSolve", "dotCall64", "dplyr", "dtplyr", "evaluate", "farver", "fields", "forcats", "foreign", "gargle", "generics", "ggplot2", "googlesheets4", "gtable", "haven", "Hmisc", "hms", "htmltools", "httr", "insight", "isoband", "jsonlite", "knitr", "lifecycle", "lme4", "maptools", "MASS", "Matrix", "MatrixModels", "metR", "mgcv", "modelr", "multcomp", "nlme", "nloptr", "nnet", "openssl", "pillar", "pkgload", "pracma", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "RCurl", "readr", "readxl", "reprex", "rlang", "rmarkdown", "rstudioapi", "rvest", "sandwich", "sass", "scales", "sensitivity", "sp", "spam", "stringi", "stringr", "Surrogate", "survival", "testthat", "tibble", "tidyr", "tidyselect", "tidyverse", "tinytex", "vctrs", "viridisLite", "vroom", "xfun", "zoo"))
install.packages(c("bayestestR", "broom", "bslib", "callr", "car", "checkmate", "cli", "cluster", "confintr", "cpp11", "crayon", "curl", "datawizard", "DBI", "dbplyr", "desc", "deSolve", "dotCall64", "dplyr", "dtplyr", "evaluate", "farver", "fields", "forcats", "foreign", "gargle", "generics", "ggplot2", "googlesheets4", "gtable", "haven", "Hmisc", "hms", "htmltools", "httr", "insight", "isoband", "jsonlite", "knitr", "lifecycle", "lme4", "maptools", "MASS", "Matrix", "MatrixModels", "metR", "mgcv", "modelr", "multcomp", "nlme", "nloptr", "nnet", "openssl", "pillar", "pkgload", "pracma", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "RCurl", "readr", "readxl", "reprex", "rlang", "rmarkdown", "rstudioapi", "rvest", "sandwich", "sass", "scales", "sensitivity", "sp", "spam", "stringi", "stringr", "Surrogate", "survival", "testthat", "tibble", "tidyr", "tidyselect", "tidyverse", "tinytex", "vctrs", "viridisLite", "vroom", "xfun", "zoo"))
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("ggplot2")
library("ggplot2")
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("bayestestR"); library("tmvtnorm")
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("bayestestR"); library("tmvtnorm")
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("bayestestR"); library("tmvtnorm")
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("bayestestR"); library("tmvtnorm")
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("bayestestR"); library("tmvtnorm")
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("bayestestR"); library("tmvtnorm")
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("bayestestR"); library("tmvtnorm")
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("bayestestR"); library("tmvtnorm")
system("uname -m")
library("tmvtnorm")
library("deSolve"); library("ggplot2"); library("reshape2"); library("ggpubr"); library("rootSolve"); library("viridis"); library("cowplot")
rm(list=ls())
setwd("/Users/amorgan/Documents/PostDoc/Diff_Tax_Analysis/Theoretical_Analysis/Diff_Taxation_new/Euler_Run/Interpolat_test/")
# Import in Dataset -------------------------------------------------------
win_import <- readRDS("MDR_run_interpol.RDS")
for(i in seq_along(win_import)) {
win_import[[i]] <- as(win_import[[i]], class(win_import[[i]][[1]]))
}
# Altering Data Infections ------------------------------------------------
#Infections
#We want to minimise this - minimise the increase in total infections for each change in usage
win_inf <- (win_import[,1:10])
#win_inf <- (win_import_pess[,1:10])
#win_inf <- (win_import_opt[,1:10])
win_inf[is.na(win_inf)] <- 0
win_inf_trans <- t(apply(win_inf, 1, function(x) {
val = min(x)
x[x != val] <- 0
x[x == val] <- 1
return(x)}
))
prop_win_inf <- data.frame("Infections" = colSums(win_inf_trans)/nrow(win_inf_trans),
"Interventions" = as.factor(c("Flat Tax", "Single Tax (HR)", "Single Tax (MR)",
"Single Tax (LR)",
"Diff Tax (1 Round)", "Diff Tax (2 Round)",
"Diff Tax (3 Round)", "Diff Tax (4 Round)",
"Diff Tax (5 Round)", "Diff Tax (6 Round)")))
prop_win_inf$Interventions <- factor(prop_win_inf$Interventions, levels = c(prop_win_inf$Interventions))
# Altering Data Resistance ------------------------------------------------
win_res <- (win_import[,11:20])
win_res[is.na(win_res)] <- 0
win_res_trans <- t(apply(win_res, 1, function(x) {
val = max(x)
x[x != val] <- 0
x[x == val] <- 1
return(x)}
))
prop_win_res <- data.frame("Resistance" = colSums(win_res_trans)/nrow(win_res_trans),
"Interventions" = as.factor(c("Flat Tax", "Single Tax (HR)", "Single Tax (MR)",
"Single Tax (LR)",
"Diff Tax (1 Round)", "Diff Tax (2 Round)",
"Diff Tax (3 Round)", "Diff Tax (4 Round)",
"Diff Tax (5 Round)", "Diff Tax (6 Round)")))
prop_win_res$Interventions <- factor(prop_win_res$Interventions, levels = c(prop_win_res$Interventions))
# Shannon's Index ---------------------------------------------------------
win_shan <- round((win_import[,21:30]), 5)
win_shan[is.na(win_shan)] <- 0
win_shan <- win_shan[rowSums(win_shan[, -1]) > 0, ]
win_shan_trans <- t(apply(win_shan, 1, function(x) {
val = max(x)
x[is.na(x)] <- 0
x[x != val] <- 0
x[x == val] <- 1
return(x)}
))
prop_win_shan <- data.frame("Shannon_Index" = colSums(win_shan_trans)/nrow(win_shan_trans),
"Interventions" = as.factor(c("Flat Tax", "Single Tax (HR)", "Single Tax (MR)",
"Single Tax (LR)",
"Diff Tax (1 Round)", "Diff Tax (2 Round)",
"Diff Tax (3 Round)", "Diff Tax (4 Round)",
"Diff Tax (5 Round)", "Diff Tax (6 Round)")))
prop_win_shan$Interventions <- factor(prop_win_shan$Interventions, levels = c(prop_win_shan$Interventions))
# Average Number of Available Antibiotics ---------------------------------
win_avganti <- round((win_import[,31:40]), 5)
win_avganti[is.na(win_avganti)] <- 0
win_avganti <- win_avganti[rowSums(win_avganti[, -1]) > 0, ]
win_avganti_trans <- t(apply(win_avganti, 1, function(x) {
val = max(x)
x[is.na(x)] <- 0
x[x != val] <- 0
x[x == val] <- 1
return(x)}
))
prop_win_avganti <- data.frame("Average_Anti" = colSums(win_avganti_trans)/nrow(win_avganti_trans),
"Interventions" = as.factor(c("Flat Tax", "Single Tax (HR)", "Single Tax (MR)",
"Single Tax (LR)",
"Diff Tax (1 Round)", "Diff Tax (2 Round)",
"Diff Tax (3 Round)", "Diff Tax (4 Round)",
"Diff Tax (5 Round)", "Diff Tax (6 Round)")))
prop_win_avganti$Interventions <- factor(prop_win_avganti$Interventions, levels = c(prop_win_avganti$Interventions))
# Combining All Together --------------------------------------------------
combdata <- prop_win_res; combdata$Infections <- prop_win_inf$Infections; combdata$Shannon <- prop_win_shan$Shannon_Index
combdata$Average_Anti <- prop_win_avganti$Average_Anti
melt_combdata <- melt(combdata, id.vars = "Interventions", measure.vars = c("Resistance", "Infections", "Shannon", "Average_Anti"))
melt_combdata$Interventions <- factor(melt_combdata$Interventions, levels = c(prop_win_res$Interventions))
# Plotting win Probabilities ----------------------------------------------
p_inf <- ggplot(prop_win_inf, aes(y = Infections, x = as.factor(Interventions))) + geom_bar(stat="identity")  + theme_bw() +
scale_x_discrete(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0), limits = c(0, 1.01)) +
labs(y ="Probability of Optimality (Preventing Infections)", x = "", fill = "") +
theme(legend.position= "bottom", legend.text=element_text(size=12), legend.title =element_text(size=12), axis.text=element_text(size=12),
axis.title.y=element_text(size=12), axis.title.x= element_text(size=12), plot.margin = unit(c(0.35,1,0.35,1), "cm"),
legend.spacing.x = unit(0.3, 'cm'), axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
p_res <- ggplot(prop_win_res, aes(y = Resistance, x = as.factor(Interventions))) + geom_bar(stat="identity") + theme_bw() +
scale_x_discrete(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0), limits = c(0, 1.01)) +
labs(y ="Probability of Optimality (Resistance Decrease)", x = "", fill = "") +
theme(legend.position= "bottom", legend.text=element_text(size=12), legend.title =element_text(size=12), axis.text=element_text(size=12),
axis.title.y=element_text(size=12), axis.title.x= element_text(size=12), plot.margin = unit(c(0.35,1,0.35,1), "cm"),
legend.spacing.x = unit(0.3, 'cm'), axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
p_shan <- ggplot(prop_win_shan, aes(y = Shannon_Index, x = as.factor(Interventions))) + geom_bar(stat="identity") + theme_bw() +
scale_x_discrete(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0), limits = c(0, 1.01)) +
labs(y ="Probability of Optimality (Highest SI)", x = "", fill = "") +
theme(legend.position= "bottom", legend.text=element_text(size=12), legend.title =element_text(size=12), axis.text=element_text(size=12),
axis.title.y=element_text(size=12), axis.title.x= element_text(size=12), plot.margin = unit(c(0.35,1,0.35,1), "cm"),
legend.spacing.x = unit(0.3, 'cm'), axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
p_avg_anti <- ggplot(prop_win_avganti, aes(y = Average_Anti, x = as.factor(Interventions))) + geom_bar(stat="identity") + theme_bw() +
scale_x_discrete(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0), limits = c(0, 1.01)) +
labs(y ="Probability of Optimality (Highest SI)", x = "", fill = "") +
theme(legend.position= "bottom", legend.text=element_text(size=12), legend.title =element_text(size=12), axis.text=element_text(size=12),
axis.title.y=element_text(size=12), axis.title.x= element_text(size=12), plot.margin = unit(c(0.35,1,0.35,1), "cm"),
legend.spacing.x = unit(0.3, 'cm'), axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
ggarrange(p_inf, p_res, p_shan, ncol = 1, nrow = 4)
#Combination Plot
p_comb <- ggplot(melt_combdata, aes(y = value, x = as.factor(Interventions), fill = variable)) +
geom_bar(stat="identity", position = position_dodge())  + theme_bw() +
scale_x_discrete(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0), limits = c(0, 1.01)) +
labs(y ="Probability of Intervention Winning", x = "", fill = "") +
theme(legend.position= "bottom", legend.text=element_text(size=12), legend.title =element_text(size=12), axis.text=element_text(size=12),
axis.title.y=element_text(size=12), axis.title.x= element_text(size=12), plot.margin = unit(c(0.35,1,0.35,1), "cm"),
legend.spacing.x = unit(0.3, 'cm'), axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
scale_fill_manual(values = c("red", "blue", "orange", "darkgreen"),labels = c("Resistance", "Infections","Shannons Index", "Average Antibiotics"))
# Proportion of Wins HeatMap ----------------------------------------------
melt_combdata$value <- round(melt_combdata$value, digits = 3)
ggplot(melt_combdata, aes(Interventions, variable)) + theme_bw() +
geom_tile(aes(fill = value)) +
facet_grid(variable ~ ., scales = "free_y") +
geom_text(aes(label=value), color = "black") +
scale_fill_distiller(palette ="Blues", direction = 1) +
scale_x_discrete(name = "", expand = c(0, 0))  +
scale_y_discrete(name = "Outcome Measure", expand = c(0, 0)) +
guides(fill = guide_colorbar(title = "Probabilty that \nIntervention Wins",
label.position = "bottom",
title.position = "left", title.vjust = 1,
# draw border around the legend
frame.colour = "black",
barwidth = 15,
barheight = 1)) +
theme(strip.background = element_blank(), axis.text=element_text(size=11),
strip.text = element_blank(), legend.position="bottom",
axis.text.x = element_text(angle = 45, hjust=1))
# Isolated Sensitivity Analysis -------------------------------------------
#For Infections and Resistance
combdata_infres <- prop_win_res; combdata_infres$Infections <- prop_win_inf$Infections
melt_combdata_infres <- melt(combdata, id.vars = "Interventions", measure.vars = c("Resistance", "Infections"))
melt_combdata_infres$Interventions <- factor(melt_combdata_infres$Interventions, levels = c(prop_win_res$Interventions))
melt_combdata_infres$value <- round(melt_combdata_infres$value, digits = 3)
ggplot(melt_combdata_infres, aes(Interventions, variable)) + theme_bw() +
geom_tile(aes(fill = value)) +
facet_grid(variable ~ ., scales = "free_y") +
geom_text(aes(label=value), color = "black") +
scale_fill_distiller(palette ="Blues", direction = 1) +
scale_x_discrete(name = "", expand = c(0, 0))  +
scale_y_discrete(name = "Outcome Measure", expand = c(0, 0)) +
guides(fill = guide_colorbar(title = "Probabilty that \nIntervention Wins",
label.position = "bottom",
title.position = "left", title.vjust = 1,
# draw border around the legend
frame.colour = "black",
barwidth = 15,
barheight = 1)) +
theme(strip.background = element_blank(), axis.text=element_text(size=11),
strip.text = element_blank(), legend.position="bottom",
axis.text.x = element_text(angle = 45, hjust=1))
#For antibiotic availability related measures
combdata_shanavg <- prop_win_shan
combdata_shanavg$Average_Anti <- prop_win_avganti$Average_Anti
melt_combdata_shanavg<- melt(combdata_shanavg, id.vars = "Interventions", measure.vars = c("Shannon_Index", "Average_Anti"))
melt_combdata_shanavg$Interventions <- factor(melt_combdata_shanavg$Interventions, levels = c(prop_win_res$Interventions))
melt_combdata_shanavg$value <- round(melt_combdata_shanavg$value, digits = 3)
ggplot(melt_combdata_shanavg, aes(Interventions, variable)) + theme_bw() +
geom_tile(aes(fill = value)) +
facet_grid(variable ~ ., scales = "free_y") +
geom_text(aes(label=value), color = "black") +
scale_fill_distiller(palette ="Blues", direction = 1) +
scale_x_discrete(name = "", expand = c(0, 0))  +
scale_y_discrete(name = "Outcome Measure", expand = c(0, 0)) +
guides(fill = guide_colorbar(title = "Probabilty that \nIntervention Wins",
label.position = "bottom",
title.position = "left", title.vjust = 1,
# draw border around the legend
frame.colour = "black",
barwidth = 15,
barheight = 1)) +
theme(strip.background = element_blank(), axis.text=element_text(size=11),
strip.text = element_blank(), legend.position="bottom",
axis.text.x = element_text(angle = 45, hjust=1))
